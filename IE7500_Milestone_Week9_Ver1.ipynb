{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e209e5-00eb-4d8f-b2d6-b59aa3386f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import torch\n",
    "\n",
    "# Load Fine-Tuned BioBERT Model\n",
    "model_path = \"./fine_tuned_biobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModel.from_pretrained(model_path)\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()  # Get embedding vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c3cb14-6596-4a38-8d64-e5b4b3be6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (update path as needed)\n",
    "df = pd.read_excel(\"MilestoneW9Data.xlsx\")\n",
    "\n",
    "# Preprocess symptoms\n",
    "df[\"Symptoms\"] = df[\"Symptoms\"].str.lower().str.replace(\", \", \",\")\n",
    "df[\"Symptom_List\"] = df[\"Symptoms\"].apply(lambda x: x.split(\",\"))\n",
    "df[\"Symptom_String\"] = df[\"Symptom_List\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Generate BioBERT embeddings\n",
    "df[\"Symptom_Embedding\"] = df[\"Symptom_String\"].apply(lambda x: get_bert_embedding(x).flatten())\n",
    "\n",
    "# Save processed dataset\n",
    "df.to_csv(\"BioBERT_Disease_Embeddings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12cf8c63-32b8-42a3-9ba6-885518dc6ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Diseases:\n",
      "                Disease                                               Note\n",
      "0           Hepatitis B  Caused by the hepatitis B virus (HBV); prevent...\n",
      "1  Mononucleosis (Mono)            Caused by the Epstein-Barr virus (EBV).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast  # Securely evaluate stored embeddings\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", timeout=1000)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", config=config)\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", config=config)\n",
    "\n",
    "# Load the processed dataset with BioBERT embeddings\n",
    "df = pd.read_csv(\"BioBERT_Disease_Embeddings.csv\")\n",
    "\n",
    "\n",
    "\n",
    "def clean_embedding(embedding_str):\n",
    "    \"\"\"\n",
    "    Cleans and converts the stored embedding string into a proper NumPy array.\n",
    "    - Replaces multiple spaces with a single space.\n",
    "    - Ensures the format is valid before conversion.\n",
    "    \"\"\"\n",
    "    cleaned_str = re.sub(r'\\s+', ',', embedding_str.strip())  # Replace spaces with commas\n",
    "    cleaned_str = cleaned_str.replace(\"[,\", \"[\").replace(\",]\", \"]\")  # Fix edge cases\n",
    "    return np.array(ast.literal_eval(cleaned_str))  # Convert string to NumPy array\n",
    "\n",
    "# Apply the cleaning function\n",
    "df[\"Symptom_Embedding\"] = df[\"Symptom_Embedding\"].apply(lambda x: clean_embedding(x))\n",
    "\n",
    "# Load BioBERT Model and Tokenizer\n",
    "#bio_bert_model = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(bio_bert_model)\n",
    "#model = AutoModel.from_pretrained(bio_bert_model)\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    \"\"\"Generate BioBERT embeddings for user input symptoms.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()  # Get embedding vector\n",
    "\n",
    "def predict_disease(user_symptoms):\n",
    "    \"\"\"\n",
    "    Predicts the most probable disease(s) based on user symptoms.\n",
    "    \"\"\"\n",
    "    # Generate BioBERT embedding for user input\n",
    "    user_embedding = get_bert_embedding(user_symptoms).flatten().reshape(1, -1)\n",
    "\n",
    "    # Compute cosine similarity with stored disease embeddings\n",
    "    stored_embeddings = np.stack(df[\"Symptom_Embedding\"].values)\n",
    "    similarity_scores = cosine_similarity(user_embedding, stored_embeddings).flatten()\n",
    "\n",
    "    # Get top 2 most similar diseases\n",
    "    top_indices = similarity_scores.argsort()[-2:][::-1]\n",
    "    predicted_diseases = df.iloc[top_indices][[\"Disease\", \"Note\"]].reset_index(drop=True)\n",
    "\n",
    "    return predicted_diseases\n",
    "\n",
    "# Example: Predict disease for user symptoms\n",
    "user_input = \"fever, chills, muscle pain, headache\"\n",
    "predicted_result = predict_disease(user_input)\n",
    "\n",
    "# Display Results\n",
    "print(\"Predicted Diseases:\")\n",
    "print(predicted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc2a83-9e11-440e-bfc9-81e5f4528dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Welcome back, Arish! Let's check your symptoms.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ You: Describe your symptoms (or type 'exit' to quit):  I am having abdominal pain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Bot: I couldn't detect any medical symptoms. Please try again.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ You: Describe your symptoms (or type 'exit' to quit):  i have fever and cough\n",
      "\n",
      "ü§ñ Bot: Do you have any other symptoms? (yes/no)  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Bot: Based on your symptoms, you **might** have:\n",
      "  - **Yellow Fever**: Yellow fever is a mosquito-borne viral disease.\n",
      "  - **Plague (Yersinia pestis)**: Rare but serious; transmitted by fleas or respiratory droplets.\n",
      "\n",
      "‚ö†Ô∏è *Disclaimer: This is not a medical diagnosis. Please consult a doctor or visit the nearest clinic for proper medical advice.*\n",
      "üè• **Nearest Clinics:**\n",
      "  - **DOCTOR_K**\n",
      "    üìç Address: Regeringsgatan 85, 111 39 Stockholm, Sweden\n",
      "    üìû 08-88 92 41\n",
      "  - **Medical**\n",
      "    üìç Address: Kommend√∂rsgatan 44, 114 58 Stockholm, Sweden\n",
      "    üìû 08-545 816 70\n",
      "  - **Diagnostiskt Centrum Hud i Stockholm City**\n",
      "    üìç Address: Apelbergsgatan 60, 111 37 Stockholm, Sweden\n",
      "    üìû 08-515 115 00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import spacy  # NLP for symptom extraction\n",
    "from IPython.display import display\n",
    "import requests  # Import this to avoid \"NameError\"\n",
    "\n",
    "# Load NLP Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# File to store user data\n",
    "USER_DATA_FILE = \"user_data.json\"\n",
    "\n",
    "# Google API Key (Replace with your actual key)\n",
    "GOOGLE_API_KEY = \"XXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "# Load dataset and BioBERT model\n",
    "df = pd.read_csv(\"BioBERT_Disease_Embeddings.csv\")\n",
    "\n",
    "def clean_embedding(embedding_str):\n",
    "    cleaned_str = re.sub(r'\\s+', ',', embedding_str.strip())\n",
    "    cleaned_str = cleaned_str.replace(\"[,\", \"[\").replace(\",]\", \"]\")\n",
    "    return np.array(ast.literal_eval(cleaned_str))\n",
    "\n",
    "df[\"Symptom_Embedding\"] = df[\"Symptom_Embedding\"].apply(lambda x: clean_embedding(x))\n",
    "\n",
    "# Extract all possible symptoms from dataset\n",
    "all_symptoms = set()\n",
    "for symptom_list in df[\"Symptoms\"]:\n",
    "    for symptom in symptom_list.split(\",\"):\n",
    "        all_symptoms.add(symptom.strip().lower())\n",
    "\n",
    "# Load BioBERT\n",
    "bio_bert_model = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bio_bert_model)\n",
    "model = AutoModel.from_pretrained(bio_bert_model)\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "def extract_symptoms(user_input):\n",
    "    doc = nlp(user_input)\n",
    "    extracted_symptoms = [token.text.lower() for token in doc if token.pos_ in [\"NOUN\", \"ADJ\"]]\n",
    "    filtered_symptoms = [symptom for symptom in extracted_symptoms if symptom in all_symptoms]\n",
    "    return \" \".join(filtered_symptoms) if filtered_symptoms else None\n",
    "\n",
    "def predict_disease(symptoms):\n",
    "    user_embedding = get_bert_embedding(symptoms).flatten().reshape(1, -1)\n",
    "    stored_embeddings = np.stack(df[\"Symptom_Embedding\"].values)\n",
    "    similarity_scores = cosine_similarity(user_embedding, stored_embeddings).flatten()\n",
    "    top_indices = similarity_scores.argsort()[-2:][::-1]\n",
    "    predicted_diseases = df.iloc[top_indices][[\"Disease\", \"Note\"]].reset_index(drop=True)\n",
    "\n",
    "    response = f\"\\nü§ñ Bot: Based on your symptoms, you **might** have:\\n\"\n",
    "    for index, row in predicted_diseases.iterrows():\n",
    "        response += f\"  - **{row['Disease']}**: {row['Note']}\\n\"\n",
    "    \n",
    "    response += \"\\n‚ö†Ô∏è *Disclaimer: This is not a medical diagnosis. Please consult a doctor or visit the nearest clinic for proper medical advice.*\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "def ask_additional_symptoms(initial_symptoms):\n",
    "    while True:\n",
    "        user_response = input(\"\\nü§ñ Bot: Do you have any other symptoms? (yes/no) \").strip().lower()\n",
    "        \n",
    "        if user_response in [\"no\", \"exit\"]:\n",
    "            return initial_symptoms\n",
    "\n",
    "        elif user_response == \"yes\":\n",
    "            extra_input = input(\"\\nüë§ You: Please describe any additional symptoms: \").strip().lower()\n",
    "            extra_symptoms = extract_symptoms(extra_input)\n",
    "\n",
    "            if extra_symptoms:\n",
    "                return f\"{initial_symptoms} {extra_symptoms}\"\n",
    "            else:\n",
    "                print(\"\\nü§ñ Bot: I couldn't detect any new symptoms. Please try again or say 'no' to proceed.\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\nü§ñ Bot: Please respond with 'yes' or 'no'.\")\n",
    "\n",
    "# Function to check if user exists and load data\n",
    "def load_user_data():\n",
    "    if os.path.exists(USER_DATA_FILE):\n",
    "        with open(USER_DATA_FILE, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    return {}\n",
    "\n",
    "# Function to register a new user\n",
    "def register_user():\n",
    "    print(\"\\nü§ñ Bot: Let's get some details before we start.\")\n",
    "    first_name = input(\"üë§ First Name: \").strip()\n",
    "    last_name = input(\"üë§ Last Name: \").strip()\n",
    "    gender = input(\"üë§ Gender (Male/Female/Other): \").strip()\n",
    "    dob = input(\"üìÖ Date of Birth (YYYY-MM-DD): \").strip()\n",
    "    phone = input(\"üìû Phone Number: \").strip()\n",
    "    email = input(\"üìß Email Address: \").strip()\n",
    "    city = input(\"üèôÔ∏è City: \").strip()\n",
    "    address = input(\"üè† Address: \").strip()\n",
    "\n",
    "    user_data = {\n",
    "        \"first_name\": first_name,\n",
    "        \"last_name\": last_name,\n",
    "        \"gender\": gender,\n",
    "        \"dob\": dob,\n",
    "        \"phone\": phone,\n",
    "        \"email\": email,\n",
    "        \"city\": city,\n",
    "        \"address\": address\n",
    "    }\n",
    "\n",
    "    with open(USER_DATA_FILE, \"w\") as file:\n",
    "        json.dump(user_data, file)\n",
    "\n",
    "    print(f\"\\nü§ñ Bot: Thank you, {first_name}! Your information has been saved.\")\n",
    "    return user_data\n",
    "\n",
    "# Function to find nearby clinics using Google Places API\n",
    "def find_nearest_clinic(city, address):\n",
    "    query = \"clinic near \" + address + \", \" + city\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/textsearch/json?query={query}&key={GOOGLE_API_KEY}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if \"results\" in data and len(data[\"results\"]) > 0:\n",
    "        response_message = \"\\nüè• **Nearest Clinics:**\\n\"\n",
    "        for clinic in data[\"results\"][:3]:  # Show top 3 clinics\n",
    "            name = clinic.get(\"name\", \"Unknown Clinic\")\n",
    "            addr = clinic.get(\"formatted_address\", \"No address available\")\n",
    "            phone = \"Phone: Not available\"\n",
    "            \n",
    "            # Try to get phone number from details API (optional)\n",
    "            place_id = clinic.get(\"place_id\")\n",
    "            details_url = f\"https://maps.googleapis.com/maps/api/place/details/json?place_id={place_id}&fields=formatted_phone_number&key={GOOGLE_API_KEY}\"\n",
    "            details_response = requests.get(details_url).json()\n",
    "            if \"result\" in details_response and \"formatted_phone_number\" in details_response[\"result\"]:\n",
    "                phone = f\"üìû {details_response['result']['formatted_phone_number']}\"\n",
    "            \n",
    "            response_message += f\"  - **{name}**\\n    üìç Address: {addr}\\n    {phone}\\n\"\n",
    "\n",
    "        return response_message\n",
    "    \n",
    "    return \"\\nü§ñ Bot: Sorry, I couldn't find any clinics near your location.\"\n",
    "\n",
    "# Chatbot Function\n",
    "def symptom_checker_chatbot():\n",
    "    user_data = load_user_data()\n",
    "\n",
    "    if not user_data:\n",
    "        user_data = register_user()\n",
    "    else:\n",
    "        print(f\"\\nü§ñ Welcome back, {user_data['first_name']}! Let's check your symptoms.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nüë§ You: Describe your symptoms (or type 'exit' to quit): \").strip().lower()\n",
    "\n",
    "        if user_input == \"exit\":\n",
    "            print(\"\\nü§ñ Bot: Thank you for using the Symptom Checker! Stay healthy! üè•\")\n",
    "            break\n",
    "\n",
    "        extracted_symptoms = extract_symptoms(user_input)\n",
    "\n",
    "        if not extracted_symptoms:\n",
    "            print(\"\\nü§ñ Bot: I couldn't detect any medical symptoms. Please try again.\")\n",
    "            continue\n",
    "\n",
    "        complete_symptoms = ask_additional_symptoms(extracted_symptoms)\n",
    "\n",
    "        response = predict_disease(complete_symptoms)\n",
    "        response += find_nearest_clinic(user_data[\"city\"], user_data[\"address\"])\n",
    "        \n",
    "        print(response)\n",
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    symptom_checker_chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c65c5a-488f-43db-9cf1-2816956305a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b752a-2b67-4be6-a4b5-d7a81a926505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c1187-857e-4a52-9d77-13f7a6126282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
